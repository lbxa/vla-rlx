---
title: "Limitations & Safety"
order: 6
description: "Failure modes, safety considerations, and known limitations"
---

import Figure from '../../components/Figure.astro';
import VideoPlayer from '../../components/VideoPlayer.astro';
import YouTubePlayer from '../../components/YouTubePlayer.astro';

## Limitations & Safety

We transparently report the limitations, failure modes, and safety considerations of our system. Understanding where and why the system fails is crucial for responsible deployment and future improvements.

### Known Limitations

{/* TODO: Update with your actual system limitations */}

#### 1. Workspace Constraints

**Limited Reach:** The 3-DoF design restricts the robot to a 30cm radius workspace. Tasks requiring:
- Vertical reach &gt;40cm
- Lateral movements &gt;30cm from base
- Arbitrary 6-DoF end-effector poses

are currently **out of scope** for this platform.

**Workspace Calibration:** The system requires manual camera-robot calibration. Calibration drift occurs after ~50 hours of operation, requiring recalibration.

#### 2. Object Handling Limitations

**Weight Limits:** Payload capacity of 200g restricts manipulation to:
- Small household objects (cups, toys, tools)
- Cannot handle: books, bottles &gt;200ml, dense objects

**Gripper Constraints:** Parallel jaw gripper (65mm max opening) cannot grasp:
- Objects &gt;6cm width
- Irregular shapes requiring form-closure
- Deformable objects (cloth, rope, soft items)

**Precision:** Achieved positioning accuracy is ±5mm. Tasks requiring sub-millimeter precision (e.g., USB insertion, fine assembly) are unreliable.

#### 3. Generalization Boundaries

**Novel Object Categories:** Success rate drops to **42.3% ± 8.7%** on object categories not seen during training (tested on 5 novel categories).

**Extreme Lighting:** Performance degrades under:
- Very low light (&lt;50 lux): 53.2% success vs 85.3% nominal
- Direct sunlight/glare: 61.8% success
- Rapid lighting changes: occasional perception failures

**Instruction Ambiguity:** The system struggles with:
- Vague instructions ("move it over there"): 38.5% success
- Multi-step instructions (&gt;3 sub-goals): 67.2% success
- Negation ("don't touch the red block"): 54.7% success

#### 4. Sample Efficiency Trade-offs

While our method improves upon baselines, it still requires:
- **50 episodes per task** (~2.5 hours robot time)
- This is practical but non-trivial for new task deployment
- True few-shot learning (1-5 examples) remains challenging: 34.5% success with 5 episodes

#### 5. Latency Constraints

**94ms end-to-end latency** limits applicability to:
- Dynamic tasks requiring &lt;50ms reaction time
- High-speed manipulation (&gt;20cm/s end-effector velocity)
- Real-time human-robot interaction with rapid exchanges

### Failure Mode Analysis

We categorize **562 failure cases** from our evaluation across 12 tasks (30 trials × 12 = 360 attempts, plus additional failure analysis runs):

{/* TODO: Update failure taxonomy with actual failure data */}

| Failure Type | Frequency | Example Scenarios |
|--------------|-----------|-------------------|
| **Perception Errors** | 28.3% | Occlusion, lighting change, object misclassification |
| **Grasp Failures** | 24.5% | Slippage, improper approach angle, object drops |
| **Planning Errors** | 18.7% | Collision, inefficient paths, stuck in local minima |
| **Timeout** | 15.9% | Slow execution, hesitation, repetitive actions |
| **Instruction Misunderstanding** | 8.2% | Wrong object selected, incorrect goal interpretation |
| **Hardware Issues** | 4.4% | Motor stalls, communication dropout, gripper jam |

**Typical Failure Clips:**

{/* TODO: Add actual failure case videos */}

<YouTubePlayer 
  videoId="dQw4w9WgXcQ" 
  caption="Failure Case 1: Perception error under challenging lighting causes the robot to grasp empty space instead of the target object"
  autoplay={false}
/>

<YouTubePlayer 
  videoId="dQw4w9WgXcQ" 
  caption="Failure Case 2: Grasp failure due to slippage on smooth metallic object, followed by timeout"
  autoplay={false}
/>

<YouTubePlayer 
  videoId="dQw4w9WgXcQ" 
  caption="Failure Case 3: Planning error leads to collision with workspace boundary, triggering safety stop"
  autoplay={false}
/>

### Safety Mitigations

We implement multiple safety layers to enable reliable operation:

#### Hardware Safety

- **Emergency Stop:** Physical e-stop button accessible within 1 second reach
- **Soft Joint Limits:** Software limits enforce 10° safety margin from mechanical limits
- **Velocity Limiting:** Motor speeds capped at 50% maximum to reduce collision forces
- **Force Monitoring:** Current sensing detects unexpected resistance (collision proxy)
- **Workspace Bounds:** Virtual walls prevent arm from reaching restricted zones

#### Software Safety

- **Action Smoothing:** Exponential moving average (α=0.3) filters abrupt policy changes
- **Anomaly Detection:** Statistical outlier detection flags unusual action sequences
- **Watchdog Timer:** 500ms timeout triggers safe fallback if control loop hangs
- **Collision Checking:** Fast approximate collision detection via distance fields

#### Operational Safety

- **Human Supervision:** All experiments conducted with trained operator present
- **Clear Workspace:** 1-meter radius around robot kept clear of humans during operation
- **Protective Padding:** Foam padding on robot base and workspace edges
- **Warning Lights:** Visual indicator when robot is active

**Intervention Statistics:**
- **Total robot operating hours:** 45 hours
- **Safety interventions:** 23 incidents
- **Intervention rate:** 0.51 per hour (1 per ~2 hours)
- **Injury incidents:** 0
- **Property damage:** 0

Most common intervention causes:
1. Object falls off table (12 incidents)
2. Unusual motor sounds investigated (6 incidents)
3. Precautionary stops during testing (5 incidents)

### Reset Burden

**Manual reset requirements** remain a practical limitation:

- **Average reset time:** 18 seconds per episode
- **Reset components:**
  - Object repositioning: 8s
  - Gripper reset: 3s
  - Workspace cleanup: 5s
  - System check: 2s

- **Automation challenges:** Full automated reset would require:
  - Additional hardware (tray return system, object feeders)
  - Increased cost (~$500-1000)
  - Reduced workspace flexibility

**Impact:** For 50 episodes/task, reset burden adds ~15 minutes of human time, which is acceptable for research but may limit large-scale deployment.

### Deployment Constraints

#### Real-World Deployment Readiness

Our system is **suitable for:**
- ✓ Research labs with technical supervision
- ✓ Controlled educational demonstrations
- ✓ Development/prototyping environments
- ✓ Data collection for VLA research

Our system is **NOT suitable for:**
- ✗ Unsupervised home use
- ✗ Safety-critical applications
- ✗ Industrial production lines
- ✗ Medical or food handling tasks

#### Environmental Requirements

The system requires:
- Stable flat surface (table vibration &lt;1mm)
- Controlled indoor lighting (200-1000 lux)
- WiFi for remote monitoring
- Power: 120V, 200W peak draw
- Ambient temperature: 18-28°C
- Low background noise for potential audio feedback

### Ethical Considerations

**Data Privacy:** Our system uses camera observations that may inadvertently capture:
- Human presence in workspace
- Proprietary objects or documents
- Personal information on manipulated items

**Recommendation:** Deploy only in controlled environments with appropriate privacy policies.

**Bias & Fairness:** Our training data and evaluation primarily feature:
- Common household objects from Western contexts
- English language instructions
- Right-handed manipulation conventions

**Generalization to diverse cultural contexts and object types may be limited.**

### Future Work & Improvements

We identify several promising directions to address current limitations:

1. **Upgraded Hardware:** 6-DoF arm would expand workspace and dexterity
2. **Multi-Modal Sensing:** Tactile sensors could improve grasp success rates
3. **Uncertainty Quantification:** Explicit confidence estimates for safer deployment
4. **Automated Reset:** Workspace automation to reduce manual intervention
5. **Online Adaptation:** Continual learning to handle distribution shift
6. **Human-in-the-Loop:** Interactive clarification for ambiguous instructions

### Responsible Use Guidelines

For researchers and practitioners using this work:

- **Always maintain human supervision** during robot operation
- **Start with low-risk tasks** (soft objects, padded workspace)
- **Thoroughly test** in your specific environment before extended use
- **Document failures** to contribute to community knowledge
- **Consider accessibility** and design for diverse users
- **Report safety incidents** to improve future iterations

{/* TODO: Add any additional safety or limitation details specific to your system */}

