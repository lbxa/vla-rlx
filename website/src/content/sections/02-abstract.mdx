---
title: "Abstract"
order: 2
description: "Research summary and key contributions"
---

import Figure from '../../components/Figure.astro';

## Abstract

{/* TODO: Replace with your actual abstract from your research paper */}
**Vision-language-action (VLA) models** have shown promise in enabling robots to follow natural language instructions for manipulation tasks. However, existing approaches typically require large-scale datasets and expensive robotic platforms. We present a novel approach that combines pre-trained VLA models with on-robot reinforcement learning to achieve effective manipulation on a low-cost 3-degree-of-freedom (3-DoF) robotic arm. Our method leverages sparse demonstrations and PPO-based fine-tuning to adapt foundation models to resource-constrained embodiments. We evaluate our approach across 12 manipulation tasks and demonstrate significant improvements in sample efficiency and task success rates compared to baseline methods.

{/* TODO: Update this abstract with your actual research problem, approach, key results, and impact */}

---

## Key Contributions

{/* TODO: Replace these contributions with your actual measurable results */}
{/* Each bullet should include concrete metrics with uncertainty estimates */}

- **Sample-Efficient Adaptation:** Achieve **85.3% ± 3.2%** success rate on novel manipulation tasks with only **50 on-robot episodes** per task, representing a **3.2× improvement** in sample efficiency compared to training from scratch.

- **Low-Cost Embodiment Transfer:** Successfully transfer OpenVLA foundation model to a **$200 3-DoF robotic arm** with **94ms end-to-end latency** at 10Hz control frequency, demonstrating practical deployment on resource-constrained hardware.

- **Robust Generalization:** Demonstrate **78.6% ± 4.1%** success rate on held-out task variations including novel objects, lighting conditions, and instruction phrasings, with **62.3% ± 5.8%** success on zero-shot task compositions.

{/* Example figure showing overall system performance */}
<Figure 
  src="/images/grad-norm.svg" 
  caption="Figure 1: Training dynamics showing gradient norm convergence during on-robot PPO fine-tuning. The model reaches stable performance within 2 hours of real-world interaction."
  alt="Gradient norm evolution during training"
/>

{/* TODO: Replace the figure above with an actual overview figure showing:
     - System architecture diagram, OR
     - Key results comparison chart, OR  
     - Representative success/failure examples
*/}
